{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5ebb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd808806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from  matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/code/MyCode/AUG/HAM10000/train.csv')\n",
    "test_df = pd.read_csv('/code/MyCode/AUG/HAM10000/test.csv')\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "train_path = '/code/MyCode/AUG/HAM10000/train_dir'\n",
    "test_path = '/code/MyCode/AUG/HAM10000/test_dir'\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Batches: \n",
      "Found 55115 images belonging to 7 classes.\n",
      "\n",
      "Test Batches: \n",
      "Found 2003 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 299\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft Attention\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "class SoftAttention(Layer):\n",
    "    def __init__(self,ch,m,concat_with_x=False,aggregate=False,**kwargs):\n",
    "        self.channels=int(ch)\n",
    "        self.multiheads = m\n",
    "        self.aggregate_channels = aggregate\n",
    "        self.concat_input_with_scaled = concat_with_x\n",
    "\n",
    "\n",
    "        super(SoftAttention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "\n",
    "        self.i_shape = input_shape\n",
    "\n",
    "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
    "\n",
    "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
    "\n",
    "        if self.aggregate_channels==False:\n",
    "\n",
    "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
    "        else:\n",
    "            if self.concat_input_with_scaled:\n",
    "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
    "            else:\n",
    "                self.out_features_shape = input_shape\n",
    "\n",
    "\n",
    "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
    "                                        initializer='he_uniform',\n",
    "                                        name='kernel_conv3d')\n",
    "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias_conv3d')\n",
    "\n",
    "        super(SoftAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        exp_x = K.expand_dims(x,axis=-1)\n",
    "\n",
    "        c3d = K.conv3d(exp_x,\n",
    "                     kernel=self.kernel_conv3d,\n",
    "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
    "        conv3d = K.bias_add(c3d,\n",
    "                        self.bias_conv3d)\n",
    "        conv3d = kl.Activation('relu')(conv3d)\n",
    "\n",
    "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
    "\n",
    "\n",
    "        conv3d = K.squeeze(conv3d, axis=-1)\n",
    "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
    "\n",
    "        softmax_alpha = K.softmax(conv3d, axis=-1)\n",
    "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
    "\n",
    "\n",
    "        if self.aggregate_channels==False:\n",
    "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)\n",
    "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
    "\n",
    "            x_exp = K.expand_dims(x,axis=-2)\n",
    "\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x_exp])\n",
    "\n",
    "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
    "\n",
    "        else:\n",
    "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
    "\n",
    "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
    "\n",
    "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
    "\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x])\n",
    "\n",
    "        if self.concat_input_with_scaled:\n",
    "            o = kl.Concatenate(axis=-1)([u,x])\n",
    "        else:\n",
    "            o = u\n",
    "\n",
    "        return [o, softmax_alpha]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(SoftAttention,self).get_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8dd308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "irv2 = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classifier_activation=\"softmax\",\n",
    "\n",
    ")\n",
    "\n",
    "# Excluding the last 28 layers of the model.\n",
    "conv = irv2.layers[-28].output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SOFT ATTENTION\n",
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n",
    "\n",
    "\n",
    "output = Flatten()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=irv2.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e09ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"/code/MyCode/AUG/Aug-Att/IRV2+SA.hdf5\")\n",
    "predictions_IRV2 = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f29f5c",
   "metadata": {},
   "source": [
    "DENSENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e1bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Batches: \n",
      "Found 55115 images belonging to 7 classes.\n",
      "\n",
      "Test Batches: \n",
      "Found 2003 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e89e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = tf.keras.applications.DenseNet201(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "\n",
    ")\n",
    "# Exclude the last 28 layers of the model.\n",
    "conv = densenet.layers[-28].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f68772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SOFT ATTENTION\n",
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n",
    "\n",
    "\n",
    "output = Flatten()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=densenet.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aae054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"/code/MyCode/AUG/Aug-Att/Densenet201+SA.hdf5\")\n",
    "predictions_Densenet = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543a082c",
   "metadata": {},
   "source": [
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53558c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Batches: \n",
      "Found 55115 images belonging to 7 classes.\n",
      "\n",
      "Test Batches: \n",
      "Found 2003 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef0ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    ")\n",
    "\n",
    "# Exclude the last 3 layers of the model.\n",
    "conv = resnet.layers[-3].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c0b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d87244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "output = GlobalAveragePooling2D()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=resnet.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"/code/MyCode/AUG/Aug-Att/ResNet50+SA.hdf5\")\n",
    "predictions_Resnet50 = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d8f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d702433",
   "metadata": {},
   "source": [
    "resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5304fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Batches: \n",
      "Found 55115 images belonging to 7 classes.\n",
      "\n",
      "Test Batches: \n",
      "Found 2003 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainInput=Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ebc03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer1(input_value):\n",
    "  conv1=Conv2D(filters=64, kernel_size=(3,3), strides=(2,2),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  conv1=BatchNormalization()(conv1)\n",
    "  pool1=MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "  return pool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc17183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer2(input_value):\n",
    "  conv2=Conv2D(filters=64, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  conv2=BatchNormalization()(conv2)\n",
    "  conv2=Conv2D(filters=64, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv2)\n",
    "  conv2=BatchNormalization()(conv2)\n",
    "\n",
    "  resnet=add([input_value,conv2])\n",
    "  resnet=Activation(\"relu\")(resnet)\n",
    "  return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1541ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer3(input_value):\n",
    "  conv3=Conv2D(filters=128, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  conv3=BatchNormalization()(conv3)\n",
    "  conv3=Conv2D(filters=128, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv3)\n",
    "  conv3=BatchNormalization()(conv3)\n",
    "\n",
    "\n",
    "  skip=Conv2D(filters=128, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  skip=BatchNormalization()(skip)\n",
    "\n",
    "  resnet=add([skip,conv3])\n",
    "  resnet=Activation(\"relu\")(resnet)\n",
    "  return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer4(input_value):\n",
    "  conv4=Conv2D(filters=256, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  conv4=BatchNormalization()(conv4)\n",
    "  conv4=Conv2D(filters=256, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv4)\n",
    "  conv4=BatchNormalization()(conv4)\n",
    "\n",
    "\n",
    "  skip=Conv2D(filters=256, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  skip=BatchNormalization()(skip)\n",
    "\n",
    "  resnet=add([skip,conv4])\n",
    "  resnet=Activation(\"relu\")(resnet)\n",
    "  return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer5(input_value):\n",
    "  conv5=Conv2D(filters=512, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  conv5=BatchNormalization()(conv5)\n",
    "  conv5=Conv2D(filters=512, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv5)\n",
    "  conv5=BatchNormalization()(conv5)\n",
    "\n",
    "\n",
    "  skip=Conv2D(filters=512, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  skip=BatchNormalization()(skip)\n",
    "\n",
    "  resnet=add([skip,conv5])\n",
    "  resnet=Activation(\"relu\")(resnet)\n",
    "  return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "block1=convlayer1(MainInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "block2=convlayer2(block1)\n",
    "for i in range(0,2):\n",
    "  block2=convlayer2(block2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool=MaxPooling2D(pool_size=(2,2), padding='same')(block2)\n",
    "block3=convlayer3(maxpool)\n",
    "\n",
    "for i in range(0,3):\n",
    "  block3=convlayer3(block3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad89f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attention_layer2,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(block3.shape[-1]),name='soft_attention')(block3)\n",
    "attention_layer2=MaxPooling2D(pool_size=(2,2), padding='same')(attention_layer2)\n",
    "maxpool=MaxPooling2D(pool_size=(2,2), padding='same')(block3)\n",
    "\n",
    "concat2=concatenate([maxpool,attention_layer2])\n",
    "conv = Activation(\"relu\")(concat2)\n",
    "conv= Dropout(0.5)(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdaeb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block4=convlayer4(conv)\n",
    "for i in range(0,5):\n",
    "  block4=convlayer4(block4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eef7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool=MaxPooling2D(pool_size=(2,2), padding='same')(block4)\n",
    "block5=convlayer5(maxpool)\n",
    "for i in range(0,2):\n",
    "  block5=convlayer5(block5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = GlobalAveragePooling2D()(block5)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=MainInput, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"/code/MyCode/AUG/Aug-Att/ResNet34+SA.hdf5\")\n",
    "predictions_Resnet34 = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d05e423",
   "metadata": {},
   "source": [
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188fdefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Batches: \n",
      "Found 55115 images belonging to 7 classes.\n",
      "\n",
      "Test Batches: \n",
      "Found 2003 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b967bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainInput=Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001647d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Conv2D(filters=64,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(MainInput))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=64,kernel_size=(1,1), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(MaxPooling2D(strides=(2, 2),padding=\"same\")(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b8a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Conv2D(filters=128,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=128,kernel_size=(1,1), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(MaxPooling2D()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edad227",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Conv2D(filters=256,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=256,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=256,kernel_size=(1,1), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e73d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(MaxPooling2D()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Conv2D(filters=512,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=512,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=512,kernel_size=(1,1), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv=Activation(\"relu\")(conv)\n",
    "conv= Dropout(0.5)(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3eca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Conv2D(filters=512,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=512,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=512,kernel_size=(1,1), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(MaxPooling2D(pool_size=(4, 4),padding=\"same\")(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52740c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba70b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Flatten()(conv))\n",
    "conv=(Dense(4096,activation=\"relu\")(conv))\n",
    "conv=(Dense(4096,activation=\"relu\")(conv))\n",
    "conv=(Dense(7, activation=\"softmax\")(conv))\n",
    "\n",
    "model = Model(inputs=MainInput, outputs=conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10afa91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"/code/MyCode/AUG/Aug-Att/vgg16+SA.hdf5\")\n",
    "predictions_VGG16 = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pred_irv2.npy\", predictions_IRV2)\n",
    "np.save(\"pred_densenet.npy\", predictions_Densenet)\n",
    "np.save(\"pred_resnet50.npy\", predictions_Resnet50)\n",
    "np.save(\"pred_resnet34.npy\", predictions_Resnet34)\n",
    "np.save(\"pred_vgg16.npy\", predictions_VGG16)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
