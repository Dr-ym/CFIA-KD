{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8befb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from zipfile import ZipFile\n",
    "filename = \"/content/drive/My Drive/HAM10000.zip\"\n",
    "\n",
    "with ZipFile(filename, 'r') as zip:\n",
    "    zip.extractall()\n",
    "    print(\"Dataset extracted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Activation, MaxPooling2D, concatenate\n",
    "from PIL import ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Paths\n",
    "train_df = pd.read_csv('/code/MyCode/AUG/HAM10000/train.csv')\n",
    "test_df = pd.read_csv('/code/MyCode/AUG/HAM10000/test.csv')\n",
    "train_path = '/code/MyCode/AUG/HAM10000/train_dir'\n",
    "test_path = '/code/MyCode/AUG/HAM10000/test_dir'\n",
    "\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "batch_size = 16\n",
    "image_size = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_batches = datagen.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_batches = datagen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "import keras.layers as kl\n",
    "\n",
    "class SoftAttention(Layer):\n",
    "    def __init__(self, ch, m, concat_with_x=False, aggregate=False, **kwargs):\n",
    "        self.channels = int(ch)\n",
    "        self.multiheads = m\n",
    "        self.aggregate_channels = aggregate\n",
    "        self.concat_input_with_scaled = concat_with_x\n",
    "        super(SoftAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.i_shape = input_shape\n",
    "        kernel_shape_conv3d = (self.channels, 3, 3, 1, self.multiheads)\n",
    "        self.out_attention_maps_shape = input_shape[0:1] + (self.multiheads,) + input_shape[1:-1]\n",
    "        if self.aggregate_channels == False:\n",
    "            self.out_features_shape = input_shape[:-1] + (input_shape[-1] + (input_shape[-1]*self.multiheads),)\n",
    "        else:\n",
    "            if self.concat_input_with_scaled:\n",
    "                self.out_features_shape = input_shape[:-1] + (input_shape[-1]*2,)\n",
    "            else:\n",
    "                self.out_features_shape = input_shape\n",
    "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
    "                                            initializer='he_uniform',\n",
    "                                            name='kernel_conv3d')\n",
    "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
    "                                          initializer='zeros',\n",
    "                                          name='bias_conv3d')\n",
    "        super(SoftAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        exp_x = K.expand_dims(x, axis=-1)\n",
    "        c3d = K.conv3d(exp_x,\n",
    "                     kernel=self.kernel_conv3d,\n",
    "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
    "        conv3d = K.bias_add(c3d, self.bias_conv3d)\n",
    "        conv3d = kl.Activation('relu')(conv3d)\n",
    "        conv3d = K.permute_dimensions(conv3d, pattern=(0,4,1,2,3))\n",
    "        conv3d = K.squeeze(conv3d, axis=-1)\n",
    "        conv3d = K.reshape(conv3d, shape=(-1, self.multiheads, self.i_shape[1]*self.i_shape[2]))\n",
    "        softmax_alpha = K.softmax(conv3d, axis=-1)\n",
    "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1], self.i_shape[2]))(softmax_alpha)\n",
    "\n",
    "        if self.aggregate_channels==False:\n",
    "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)\n",
    "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha, pattern=(0,2,3,1,4))\n",
    "            x_exp = K.expand_dims(x, axis=-2)\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x_exp])\n",
    "            u = kl.Reshape(target_shape=(self.i_shape[1], self.i_shape[2], u.shape[-1]*u.shape[-2]))(u)\n",
    "        else:\n",
    "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha, pattern=(0,2,3,1))\n",
    "            exp_softmax_alpha = K.sum(exp_softmax_alpha, axis=-1)\n",
    "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x])\n",
    "\n",
    "        if self.concat_input_with_scaled:\n",
    "            o = kl.Concatenate(axis=-1)([u, x])\n",
    "        else:\n",
    "            o = u\n",
    "\n",
    "        return [o, softmax_alpha]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [self.out_features_shape, self.out_attention_maps_shape]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "# Load EfficientNetB0\n",
    "efficientnet = EfficientNetB0(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_shape=(image_size, image_size, 3)\n",
    ")\n",
    "\n",
    "# Exclude last 28 layers for attention\n",
    "conv = efficientnet.layers[-28].output\n",
    "\n",
    "# Soft Attention\n",
    "attention_layer, map2 = SoftAttention(\n",
    "    aggregate=True, m=16, concat_with_x=False, ch=int(conv.shape[-1]), name='soft_attention'\n",
    ")(conv)\n",
    "\n",
    "attention_layer = MaxPooling2D(pool_size=(2,2), padding=\"same\")(attention_layer)\n",
    "conv = MaxPooling2D(pool_size=(2,2), padding=\"same\")(conv)\n",
    "\n",
    "conv = concatenate([conv, attention_layer])\n",
    "conv = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n",
    "\n",
    "output = Flatten()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "\n",
    "# Model\n",
    "model = Model(inputs=efficientnet.input, outputs=output)\n",
    "\n",
    "# Compile\n",
    "opt1 = tf.keras.optimizers.Adam(learning_rate=0.01, epsilon=0.1)\n",
    "model.compile(optimizer=opt1, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='/content/drive/My Drive/EfficientNetB0+SA.hdf5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=40,\n",
    "    min_delta=0.001\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_batches,\n",
    "    steps_per_epoch=len(train_df)//batch_size,\n",
    "    epochs=50,\n",
    "    verbose=2,\n",
    "    validation_data=test_batches,\n",
    "    validation_steps=len(test_df)//batch_size,\n",
    "    callbacks=[checkpoint, earlystop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0adbb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights\n",
    "model.load_weights('/content/drive/My Drive/EfficientNetB0+SA.hdf5')\n",
    "\n",
    "predictions = model.predict(test_batches, steps=len(test_df)//batch_size, verbose=0)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_batches.classes\n",
    "y_prob = predictions\n",
    "y_test = to_categorical(y_true)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred, target_names=targetnames))\n",
    "\n",
    "# Confusion matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm, targetnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637656be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "for i in range(7):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(f\"ROC AUC {targetnames[i]}: {roc_auc[i]:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "colors = ['v-', 'c', 'b', 'g', 'y', 'o-', 'r']\n",
    "for i, color in enumerate(colors):\n",
    "    plt.plot(fpr[i], tpr[i], color, label=f'{targetnames[i]} (area = {roc_auc[i]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves EfficientNetB0+SA')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_model = Model(model.inputs, model.get_layer('soft_attention').output)\n",
    "\n",
    "for i in range(len(test_batches)):\n",
    "    x_test, y_test_batch = test_batches[i]\n",
    "    sa_features, sa_maps = sa_model.predict(x_test)\n",
    "    class_predictions = model.predict(x_test)\n",
    "\n",
    "    for j in range(len(x_test)):\n",
    "        t = (x_test + 1)/2\n",
    "        fig, axes = plt.subplots(2,1, figsize=(5,10))\n",
    "        axes[0].imshow(t[j])\n",
    "        pred_idx = np.argmax(class_predictions[j])\n",
    "        gt_idx = np.argmax(y_test_batch[j])\n",
    "        pred = targetnames[pred_idx]\n",
    "        gt = targetnames[gt_idx]\n",
    "        sum_attnmap = np.sum(sa_maps[j], 0)\n",
    "        axes[1].imshow(t[j], alpha=1.0)\n",
    "        axes[1].imshow(cv2.resize(sum_attnmap, (224,224), interpolation=cv2.INTER_CUBIC), cmap='jet', alpha=0.5)\n",
    "        axes[1].set_xlabel(f\"Pred: {pred}, GT: {gt}\")\n",
    "        plt.tight_layout()\n",
    "        if pred == gt:\n",
    "            plt.savefig(f'densenet/trueCases/plt_{i}_{j}.jpg')\n",
    "        else:\n",
    "            plt.savefig(f'densenet/failCases/plt_{i}_{j}.jpg')\n",
    "        plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
