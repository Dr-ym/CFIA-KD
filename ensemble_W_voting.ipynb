{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5ebb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd808806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from  matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/code/MyCode/AUG/HAM10000/train.csv')\n",
    "test_df = pd.read_csv('/code/MyCode/AUG/HAM10000/test.csv')\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "train_path = '/code/MyCode/AUG/HAM10000/train_dir'\n",
    "test_path = '/code/MyCode/AUG/HAM10000/test_dir'\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 299\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft Attention\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "class SoftAttention(Layer):\n",
    "    def __init__(self,ch,m,concat_with_x=False,aggregate=False,**kwargs):\n",
    "        self.channels=int(ch)\n",
    "        self.multiheads = m\n",
    "        self.aggregate_channels = aggregate\n",
    "        self.concat_input_with_scaled = concat_with_x\n",
    "\n",
    "\n",
    "        super(SoftAttention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "\n",
    "        self.i_shape = input_shape\n",
    "\n",
    "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
    "\n",
    "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
    "\n",
    "        if self.aggregate_channels==False:\n",
    "\n",
    "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
    "        else:\n",
    "            if self.concat_input_with_scaled:\n",
    "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
    "            else:\n",
    "                self.out_features_shape = input_shape\n",
    "\n",
    "\n",
    "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
    "                                        initializer='he_uniform',\n",
    "                                        name='kernel_conv3d')\n",
    "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias_conv3d')\n",
    "\n",
    "        super(SoftAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        exp_x = K.expand_dims(x,axis=-1)\n",
    "\n",
    "        c3d = K.conv3d(exp_x,\n",
    "                     kernel=self.kernel_conv3d,\n",
    "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
    "        conv3d = K.bias_add(c3d,\n",
    "                        self.bias_conv3d)\n",
    "        conv3d = kl.Activation('relu')(conv3d)\n",
    "\n",
    "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
    "\n",
    "\n",
    "        conv3d = K.squeeze(conv3d, axis=-1)\n",
    "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
    "\n",
    "        softmax_alpha = K.softmax(conv3d, axis=-1)\n",
    "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
    "\n",
    "\n",
    "        if self.aggregate_channels==False:\n",
    "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)\n",
    "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
    "\n",
    "            x_exp = K.expand_dims(x,axis=-2)\n",
    "\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x_exp])\n",
    "\n",
    "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
    "\n",
    "        else:\n",
    "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
    "\n",
    "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
    "\n",
    "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
    "\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x])\n",
    "\n",
    "        if self.concat_input_with_scaled:\n",
    "            o = kl.Concatenate(axis=-1)([u,x])\n",
    "        else:\n",
    "            o = u\n",
    "\n",
    "        return [o, softmax_alpha]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(SoftAttention,self).get_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8dd308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "irv2 = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classifier_activation=\"softmax\",\n",
    "\n",
    ")\n",
    "\n",
    "# Excluding the last 28 layers of the model.\n",
    "conv = irv2.layers[-28].output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SOFT ATTENTION\n",
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n",
    "\n",
    "\n",
    "output = Flatten()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=irv2.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e09ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"/code/MyCode/AUG/Aug-Att/IRV2+SA.hdf5\")\n",
    "predictions_IRV2 = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f29f5c",
   "metadata": {},
   "source": [
    "DENSENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e1bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e89e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = tf.keras.applications.DenseNet201(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "\n",
    ")\n",
    "# Exclude the last 28 layers of the model.\n",
    "conv = densenet.layers[-28].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f68772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SOFT ATTENTION\n",
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n",
    "\n",
    "\n",
    "output = Flatten()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=densenet.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aae054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"/code/MyCode/AUG/Aug-Att/Densenet201+SA.hdf5\")\n",
    "predictions_Densenet = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543a082c",
   "metadata": {},
   "source": [
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53558c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef0ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    ")\n",
    "\n",
    "# Exclude the last 3 layers of the model.\n",
    "conv = resnet.layers[-3].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c0b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d87244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "output = GlobalAveragePooling2D()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=resnet.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"/code/MyCode/AUG/Aug-Att/ResNet50+SA.hdf5\")\n",
    "predictions_Resnet50 = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d8f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d702433",
   "metadata": {},
   "source": [
    "resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5304fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainInput=Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ebc03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer1(input_value):\n",
    "  conv1=Conv2D(filters=64, kernel_size=(3,3), strides=(2,2),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  conv1=BatchNormalization()(conv1)\n",
    "  pool1=MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "  return pool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc17183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer2(input_value):\n",
    "  conv2=Conv2D(filters=64, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  conv2=BatchNormalization()(conv2)\n",
    "  conv2=Conv2D(filters=64, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv2)\n",
    "  conv2=BatchNormalization()(conv2)\n",
    "\n",
    "  resnet=add([input_value,conv2])\n",
    "  resnet=Activation(\"relu\")(resnet)\n",
    "  return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1541ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer3(input_value):\n",
    "  conv3=Conv2D(filters=128, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  conv3=BatchNormalization()(conv3)\n",
    "  conv3=Conv2D(filters=128, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv3)\n",
    "  conv3=BatchNormalization()(conv3)\n",
    "\n",
    "\n",
    "  skip=Conv2D(filters=128, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  skip=BatchNormalization()(skip)\n",
    "\n",
    "  resnet=add([skip,conv3])\n",
    "  resnet=Activation(\"relu\")(resnet)\n",
    "  return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer4(input_value):\n",
    "  conv4=Conv2D(filters=256, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  conv4=BatchNormalization()(conv4)\n",
    "  conv4=Conv2D(filters=256, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv4)\n",
    "  conv4=BatchNormalization()(conv4)\n",
    "\n",
    "\n",
    "  skip=Conv2D(filters=256, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  skip=BatchNormalization()(skip)\n",
    "\n",
    "  resnet=add([skip,conv4])\n",
    "  resnet=Activation(\"relu\")(resnet)\n",
    "  return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlayer5(input_value):\n",
    "  conv5=Conv2D(filters=512, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  conv5=BatchNormalization()(conv5)\n",
    "  conv5=Conv2D(filters=512, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(conv5)\n",
    "  conv5=BatchNormalization()(conv5)\n",
    "\n",
    "\n",
    "  skip=Conv2D(filters=512, kernel_size=(3,3),activation=\"relu\",padding=\"same\")(input_value)\n",
    "  skip=BatchNormalization()(skip)\n",
    "\n",
    "  resnet=add([skip,conv5])\n",
    "  resnet=Activation(\"relu\")(resnet)\n",
    "  return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "block1=convlayer1(MainInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "block2=convlayer2(block1)\n",
    "for i in range(0,2):\n",
    "  block2=convlayer2(block2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool=MaxPooling2D(pool_size=(2,2), padding='same')(block2)\n",
    "block3=convlayer3(maxpool)\n",
    "\n",
    "for i in range(0,3):\n",
    "  block3=convlayer3(block3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad89f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attention_layer2,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(block3.shape[-1]),name='soft_attention')(block3)\n",
    "attention_layer2=MaxPooling2D(pool_size=(2,2), padding='same')(attention_layer2)\n",
    "maxpool=MaxPooling2D(pool_size=(2,2), padding='same')(block3)\n",
    "\n",
    "concat2=concatenate([maxpool,attention_layer2])\n",
    "conv = Activation(\"relu\")(concat2)\n",
    "conv= Dropout(0.5)(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdaeb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block4=convlayer4(conv)\n",
    "for i in range(0,5):\n",
    "  block4=convlayer4(block4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eef7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool=MaxPooling2D(pool_size=(2,2), padding='same')(block4)\n",
    "block5=convlayer5(maxpool)\n",
    "for i in range(0,2):\n",
    "  block5=convlayer5(block5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = GlobalAveragePooling2D()(block5)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=MainInput, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"/code/MyCode/AUG/Aug-Att/ResNet34+SA.hdf5\")\n",
    "predictions_Resnet34 = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d05e423",
   "metadata": {},
   "source": [
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188fdefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b967bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainInput=Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001647d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Conv2D(filters=64,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(MainInput))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=64,kernel_size=(1,1), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(MaxPooling2D(strides=(2, 2),padding=\"same\")(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b8a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Conv2D(filters=128,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=128,kernel_size=(1,1), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(MaxPooling2D()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edad227",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Conv2D(filters=256,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=256,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=256,kernel_size=(1,1), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e73d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(MaxPooling2D()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Conv2D(filters=512,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=512,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=512,kernel_size=(1,1), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv=Activation(\"relu\")(conv)\n",
    "conv= Dropout(0.5)(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3eca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Conv2D(filters=512,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=512,kernel_size=(3,3), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))\n",
    "conv=(Conv2D(filters=512,kernel_size=(1,1), activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(conv))\n",
    "conv=(BatchNormalization()(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(MaxPooling2D(pool_size=(4, 4),padding=\"same\")(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52740c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba70b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=(Flatten()(conv))\n",
    "conv=(Dense(4096,activation=\"relu\")(conv))\n",
    "conv=(Dense(4096,activation=\"relu\")(conv))\n",
    "conv=(Dense(7, activation=\"softmax\")(conv))\n",
    "\n",
    "model = Model(inputs=MainInput, outputs=conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10afa91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"/code/MyCode/AUG/Aug-Att/vgg16+SA.hdf5\")\n",
    "predictions_VGG16 = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81aeab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeddb849",
   "metadata": {},
   "source": [
    "Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af364e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_Densenet = 0.1935\n",
    "weight_IRV2 = 0.3441\n",
    "weight_Resnet50 = 0.1398\n",
    "weight_Resnet34 = 0.1183\n",
    "weight_VGG16 = 0.2043 \n",
    "\n",
    "# Perform ensemble voting with weighted averaging\n",
    "ensemble_predictions = (weight_Densenet * predictions_Densenet) + (weight_IRV2 * predictions_IRV2) + (weight_Resnet50 * predictions_Resnet50) + (weight_Resnet34 * predictions_Resnet34) + (weight_VGG16 * predictions_VGG16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tabulate import tabulate\n",
    "import csv\n",
    "\n",
    "\n",
    "# Getting predictions on test dataset\n",
    "y_pred = np.argmax(ensemble_predictions, axis=1)\n",
    "\n",
    "# Getting the true labels per image\n",
    "y_true = test_batches.classes\n",
    "\n",
    "# Creating classification report\n",
    "report = classification_report(y_true, y_pred, target_names=targetnames, output_dict=True)\n",
    "\n",
    "# Calculate standard deviation for each class\n",
    "std_deviation = np.std(ensemble_predictions, axis=0)\n",
    "\n",
    "# Modify existing report table to include standard deviation\n",
    "for i, label in enumerate(targetnames):\n",
    "    report[label]['precision'] = f\"{report[label]['precision']:.2f} ± {std_deviation[i]:.2f}\"\n",
    "    report[label]['recall'] = f\"{report[label]['recall']:.2f} ± {std_deviation[i]:.2f}\"\n",
    "    report[label]['f1-score'] = f\"{report[label]['f1-score']:.2f} ± {std_deviation[i]:.2f}\"\n",
    "\n",
    "# Convert report to a list of lists for tabulate\n",
    "table_data = []\n",
    "for label, metrics in report.items():\n",
    "    if label != 'accuracy':\n",
    "        row = [label]\n",
    "        for metric, value in metrics.items():\n",
    "            row.append(value)\n",
    "        table_data.append(row)\n",
    "\n",
    "# Print classification report table\n",
    "print(\"\\nClassification Report DenseNet201+SA:\")\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"]\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Save the table to a CSV file\n",
    "csv_filename = \"classification_report_densenet_SA.csv\"\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(headers)  # Write headers\n",
    "    csv_writer.writerows(table_data)  # Write data\n",
    "print(f\"Classification report saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import classification_report\n",
    "import csv\n",
    "\n",
    "# Assuming you already have predictions, y_true, and targetnames defined\n",
    "\n",
    "# Getting predictions on test dataset\n",
    "y_pred = np.argmax(ensemble_predictions, axis=1)\n",
    "\n",
    "# Getting the true labels per image\n",
    "y_true = test_batches.classes\n",
    "\n",
    "# Creating classification report\n",
    "report = classification_report(y_true, y_pred, target_names=targetnames, output_dict=True)\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "accuracies = []\n",
    "std_deviations = []\n",
    "class_counts = []\n",
    "for i, label in enumerate(targetnames):\n",
    "    correct_predictions = np.logical_and(y_true == i, y_true == y_pred)\n",
    "    accuracy = np.sum(correct_predictions) / np.sum(y_true == i)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    # Calculate standard deviation for this class\n",
    "    std_deviation = np.std(correct_predictions.astype(int))\n",
    "    std_deviations.append(std_deviation)\n",
    "\n",
    "    # Count instances of this class\n",
    "    class_counts.append(np.sum(y_true == i))\n",
    "\n",
    "# Calculate weighted average accuracy\n",
    "weighted_accuracy = np.sum(np.array(accuracies) * np.array(class_counts)) / np.sum(class_counts)\n",
    "\n",
    "# Convert accuracy and standard deviation data to a list of lists for tabulate\n",
    "table_data = []\n",
    "for i, label in enumerate(targetnames):\n",
    "    table_data.append([label, f\"{accuracies[i]:.2f} ± {std_deviations[i]:.2f}\"])\n",
    "\n",
    "# Add overall average accuracy to the table data\n",
    "table_data.append([\"Weighted Avg\", f\"{weighted_accuracy:.2f}\"])\n",
    "\n",
    "# Print accuracy with standard deviation for each class in tabular format\n",
    "print(\"\\nAccuracy with Standard Deviation for Each Class:\")\n",
    "headers = [\"Class\", \"Accuracy\"]\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Save the table to a CSV file\n",
    "csv_filename = \"accuracy_report_densenetSA_acc.csv\"\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(headers)  # Write headers\n",
    "    csv_writer.writerows(table_data)  # Write data\n",
    "print(f\"Accuracy report saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b12c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix Weighted Voting',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = targetnames) \n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Pred Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de2e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#geting predictions on test dataset\n",
    "y_pred = np.argmax(ensemble_predictions, axis=1)\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "#getting the true labels per image\n",
    "y_true = test_batches.classes\n",
    "#getting the predicted labels per image\n",
    "y_prob=ensemble_predictions\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test = to_categorical(y_true)\n",
    "\n",
    "# Creating classification report\n",
    "report = classification_report(y_true, y_pred, target_names=targetnames)\n",
    "\n",
    "print(\"\\nClassification Report DenseNet201+SA:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcfcf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average = 'weighted'\")\n",
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"Roc score: \" + str(roc_auc_score(y_test,y_prob,multi_class='ovr',average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(7):\n",
    "    r = roc_auc_score(y_test[:, i], y_prob[:, i])\n",
    "    print(\"The ROC AUC score of \"+targetnames[i]+\" is: \"+str(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d5a3c",
   "metadata": {},
   "source": [
    "Analyze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0086d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34848c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "sa_model = Model(model.inputs, model.get_layer('soft_attention').output)\n",
    "target_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "\n",
    "# Open a CSV file for writing\n",
    "with open('output.csv', 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "\n",
    "    # Write header row\n",
    "    csvwriter.writerow(['id', 'pred', 'gt'])\n",
    "\n",
    "    for i in range(len(test_batches)):\n",
    "        x_test, y_test = test_batches[i]\n",
    "        sa_features, sa_maps = sa_model.predict(x_test)\n",
    "        for j in range(len(x_test)):\n",
    "            img_idx = j\n",
    "            class_predictions = model.predict(x_test)\n",
    "\n",
    "            prediction_index = np.argmax(class_predictions[j])\n",
    "            ground_truth_index = np.argmax(y_test[j])\n",
    "            pred = target_names[prediction_index]\n",
    "            gt = target_names[ground_truth_index]\n",
    "\n",
    "            # Write row to CSV\n",
    "            csvwriter.writerow([f\"{i}_{j}\", pred, gt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_model = Model(model.inputs,model.get_layer('soft_attention').output)\n",
    "target_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "\n",
    "\n",
    "for i in range(len(test_batches)):\n",
    "    x_test,y_test=test_batches[i]\n",
    "    sa_features, sa_maps = sa_model.predict(x_test)\n",
    "    for j in range(len(x_test)):\n",
    "        img_idx = j\n",
    "        t = (x_test + 1)/2 \n",
    "        fig, axes = plt.subplots(2, 1)\n",
    "        axes[0].imshow(t[img_idx])\n",
    "        class_predictions = model.predict(x_test)\n",
    "\n",
    "        prediction_index = np.argmax(class_predictions[j])\n",
    "        ground_truth_index = np.argmax(y_test[j])\n",
    "        pred = target_names[prediction_index]\n",
    "        gt = target_names[ground_truth_index]\n",
    "        \n",
    "        sum_attnmap = np.sum(sa_maps[img_idx],0)\n",
    "        axes[1].imshow(t[img_idx],alpha=1.0)\n",
    "        axes[1].imshow(cv2.resize(sum_attnmap,(224,224),interpolation=cv2.INTER_CUBIC),cmap='jet',alpha=0.5)\n",
    "        axes[1].set_xlabel(f\"Pred: {pred}, Gt: {gt}\")\n",
    "        \n",
    "        if (pred == gt):\n",
    "            plt.savefig('trueCases/plt_' + str(i) + '_' + str(j) + '.jpg')\n",
    "        else: \n",
    "            plt.savefig('failCases/plt_' + str(i) + '_' + str(j) + '.jpg')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
