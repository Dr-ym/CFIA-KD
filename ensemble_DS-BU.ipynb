{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d0d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef1fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions\n",
    "predictions_IRV2      = np.load(\"predictions_IRV2.npy\")\n",
    "predictions_Densenet  = np.load(\"predictions_Densenet.npy\")\n",
    "predictions_Resnet50  = np.load(\"predictions_Resnet50.npy\")\n",
    "predictions_Resnet34  = np.load(\"predictions_Resnet34.npy\")\n",
    "predictions_VGG16     = np.load(\"predictions_VGG16.npy\")\n",
    "\n",
    "y_true = np.load(\"y_true.npy\")\n",
    "\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "\n",
    "all_preds = [predictions_IRV2, predictions_Densenet, predictions_Resnet50,\n",
    "             predictions_Resnet34, predictions_VGG16]\n",
    "\n",
    "N, C = predictions_IRV2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ff86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mass(m):\n",
    "    s = np.sum(m)\n",
    "    return m / s if s != 0 else m\n",
    "\n",
    "def ds_combine_two(m1, m2):\n",
    "    C = m1.shape[0]\n",
    "    m_comb = np.zeros(C)\n",
    "    conflict = 0.0\n",
    "\n",
    "    for i in range(C):\n",
    "        for j in range(C):\n",
    "            if i == j:\n",
    "                m_comb[i] += m1[i] * m2[j]\n",
    "            else:\n",
    "                conflict += m1[i] * m2[j]\n",
    "\n",
    "    if conflict < 1.0:\n",
    "        m_comb = m_comb / (1.0 - conflict)\n",
    "    else:\n",
    "        m_comb = (m1 + m2) / 2.0\n",
    "\n",
    "    return normalize_mass(m_comb)\n",
    "\n",
    "def ds_fusion(predictions_list):\n",
    "    fused = predictions_list[0].copy()\n",
    "    for preds in predictions_list[1:]:\n",
    "        for i in range(fused.shape[0]):\n",
    "            fused[i] = ds_combine_two(fused[i], preds[i])\n",
    "    return fused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_ds = ds_fusion(all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0022eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_array = np.stack(all_preds, axis=0)  \n",
    "disagreement = np.std(all_preds_array, axis=0).mean(axis=1)  \n",
    "\n",
    "threshold = disagreement.mean() + disagreement.std()\n",
    "print(f\"Disagreement threshold: {threshold:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da50837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_update(prior, predictions_list, eps=1e-8):\n",
    "   \n",
    "    log_post = np.log(prior + eps)\n",
    "    for pred in predictions_list:\n",
    "        log_post += np.log(pred + eps)\n",
    "    posterior = np.exp(log_post)\n",
    "    posterior /= posterior.sum()\n",
    "    return posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_hybrid = np.zeros_like(teacher_ds)\n",
    "\n",
    "for i in range(N):\n",
    "    if disagreement[i] <= threshold:\n",
    "        # Low disagreement → keep DS output\n",
    "        teacher_hybrid[i] = teacher_ds[i]\n",
    "    else:\n",
    "        # High disagreement → use DS as prior + Bayesian update\n",
    "        sample_preds = [pred[i] for pred in all_preds]\n",
    "        teacher_hybrid[i] = bayesian_update(teacher_ds[i], sample_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f23a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"teacher_hybrid_probs.npy\", teacher_hybrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5264cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hybrid = np.argmax(teacher_hybrid, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_hybrid, target_names=targetnames))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_hybrid)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cm)\n",
    "plt.title(\"Hybrid DS + Bayesian Teacher – Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(7), targetnames, rotation=45)\n",
    "plt.yticks(range(7), targetnames)\n",
    "\n",
    "thresh_cm = cm.max() / 2\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh_cm else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96295b2d",
   "metadata": {},
   "source": [
    "XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62467ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8fdd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lrp(model, data_generator, method=\"lrp.epsilon\"):\n",
    "\n",
    "    analyzer = innvestigate.create_analyzer(method, model)\n",
    "\n",
    "    all_relevances = []\n",
    "    steps = len(data_generator)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        x_batch, y_batch = data_generator[i]\n",
    "        relevances = analyzer.analyze(x_batch)\n",
    "        all_relevances.append(relevances)\n",
    "    \n",
    "    all_relevances = np.concatenate(all_relevances, axis=0)\n",
    "    return all_relevances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "models_and_names = {\n",
    "    \"IRV2\": \"/code/MyCode/AUG/Aug-Att/IRV2+SA.hdf5\",\n",
    "    \"Densenet201\": \"/code/MyCode/AUG/Aug-Att/Densenet201+SA.hdf5\",\n",
    "    \"ResNet50\": \"/code/MyCode/AUG/Aug-Att/ResNet50+SA.hdf5\",\n",
    "    \"ResNet34\": \"/code/MyCode/AUG/Aug-Att/ResNet34+SA.hdf5\",\n",
    "    \"VGG16\": \"/code/MyCode/AUG/Aug-Att/vgg16+SA.hdf5\"\n",
    "}\n",
    "\n",
    "for model_name, model_path in models_and_names.items():\n",
    "    print(f\"Processing LRP for {model_name}...\")\n",
    "    model = load_model(model_path, compile=False)\n",
    "    \n",
    "    relevances = compute_lrp(model, test_batches, method=\"lrp.epsilon\")\n",
    "    \n",
    "    np.save(f\"LRP_{model_name}.npy\", relevances)\n",
    "    print(f\"Saved LRP_{model_name}.npy with shape {relevances.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f7a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301c16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfe49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lrp_IRV2      = np.load(\"LRP_IRV2.npy\")\n",
    "lrp_Densenet  = np.load(\"LRP_Densenet201.npy\")\n",
    "lrp_ResNet50  = np.load(\"LRP_ResNet50.npy\")\n",
    "lrp_ResNet34  = np.load(\"LRP_ResNet34.npy\")\n",
    "lrp_VGG16     = np.load(\"LRP_VGG16.npy\")\n",
    "\n",
    "all_lrp = [lrp_IRV2, lrp_Densenet, lrp_ResNet50, lrp_ResNet34, lrp_VGG16]\n",
    "\n",
    "print(\"LRP shapes:\", [l.shape for l in all_lrp])\n",
    "N, H, W, C = lrp_IRV2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc94f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mass_map(m):\n",
    "    s = np.sum(m)\n",
    "    return m / s if s != 0 else m\n",
    "\n",
    "def ds_combine_two_map(m1, m2):\n",
    "    \"\"\"\n",
    "    Apply DS fusion on 3D or 4D importance maps (H,W,C)\n",
    "    \"\"\"\n",
    "    m_comb = np.zeros_like(m1)\n",
    "    conflict = 0.0\n",
    "    \n",
    "    flat1 = m1.flatten()\n",
    "    flat2 = m2.flatten()\n",
    "    \n",
    "    for i in range(len(flat1)):\n",
    "        for j in range(len(flat2)):\n",
    "            if i == j:\n",
    "                m_comb.flat[i] += flat1[i] * flat2[j]\n",
    "            else:\n",
    "                conflict += flat1[i] * flat2[j]\n",
    "\n",
    "    if conflict < 1.0:\n",
    "        m_comb = m_comb / (1.0 - conflict)\n",
    "    else:\n",
    "        m_comb = (m1 + m2) / 2.0\n",
    "    \n",
    "    return normalize_mass_map(m_comb)\n",
    "\n",
    "def ds_fusion_map(lrp_list):\n",
    "    fused = lrp_list[0].copy()\n",
    "    for lrp in lrp_list[1:]:\n",
    "        for i in range(fused.shape[0]):\n",
    "            fused[i] = ds_combine_two_map(fused[i], lrp[i])\n",
    "    return fused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08656f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp_ds = ds_fusion_map(all_lrp)\n",
    "print(\"LRP DS fusion done, shape:\", lrp_ds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lrp_array = np.stack(all_lrp, axis=0)  # shape: (num_models, N, H, W, C)\n",
    "disagreement = np.std(all_lrp_array, axis=0).mean(axis=(1,2,3))  # mean over H,W,C\n",
    "\n",
    "threshold = disagreement.mean() + disagreement.std()\n",
    "print(f\"LRP disagreement threshold: {threshold:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_update_map(prior_map, maps_list, eps=1e-8):\n",
    "    log_post = np.log(prior_map + eps)\n",
    "    for m in maps_list:\n",
    "        log_post += np.log(m + eps)\n",
    "    posterior = np.exp(log_post)\n",
    "    posterior /= posterior.sum()\n",
    "    return posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3301d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp_hybrid = np.zeros_like(lrp_ds)\n",
    "\n",
    "for i in range(N):\n",
    "    if disagreement[i] <= threshold:\n",
    "        # low disagreement → keep DS map\n",
    "        lrp_hybrid[i] = lrp_ds[i]\n",
    "    else:\n",
    "        # high disagreement → use DS as prior + Bayesian update\n",
    "        sample_maps = [lrp[i] for lrp in all_lrp]\n",
    "        lrp_hybrid[i] = bayesian_update_map(lrp_ds[i], sample_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"LRP_hybrid.npy\", lrp_hybrid)\n",
    "print(\"Saved LRP_hybrid.npy with shape:\", lrp_hybrid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92447dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/code/MyCode/AUG/HAM10000/test_dir'\n",
    "\n",
    "test_batches = datagen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "steps_test = len(test_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849bc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_teacher = model.predict(test_batches, steps=steps_test, verbose=1)\n",
    "np.save(\"teacher_predictions.npy\", predictions_teacher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_lrp_test = []\n",
    "test_batches.reset()\n",
    "\n",
    "for i in range(steps_test):\n",
    "    X_batch, _ = test_batches.next()\n",
    "    lrp_batch = compute_lrp(model, X_batch)  # LRP-0 for teacher\n",
    "    teacher_lrp_test.append(lrp_batch)\n",
    "\n",
    "teacher_lrp_test = np.vstack(teacher_lrp_test)\n",
    "np.save(\"teacher_LRP.npy\", teacher_lrp_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_batch, _ = test_batches.next()\n",
    "idx = 0\n",
    "\n",
    "img = X_batch[idx]\n",
    "lrp = teacher_lrp_test[idx].squeeze()\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(8,4))\n",
    "axes[0].imshow((img - img.min()) / (img.max() - img.min()))\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(lrp, cmap='hot')\n",
    "axes[1].set_title(\"Teacher LRP\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
